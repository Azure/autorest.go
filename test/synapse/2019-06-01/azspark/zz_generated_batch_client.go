//go:build go1.18
// +build go1.18

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

package azspark

import (
	"context"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/policy"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/runtime"
	"net/http"
	"net/url"
	"strconv"
	"strings"
)

type batchClient struct {
	endpoint string
	pl       runtime.Pipeline
}

// newBatchClient creates a new instance of batchClient with the specified values.
// endpoint - The workspace development endpoint, for example https://myworkspace.dev.azuresynapse.net.
// livyAPIVersion - Valid api-version for the request.
// sparkPoolName - Name of the spark pool.
// pl - the pipeline used for sending requests and handling responses.
func newBatchClient(endpoint string, livyAPIVersion *string, sparkPoolName string, pl runtime.Pipeline) *batchClient {
	hostURL := "{endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}"
	hostURL = strings.ReplaceAll(hostURL, "{endpoint}", endpoint)
	if livyAPIVersion == nil {
		defaultValue := "2019-11-01-preview"
		livyAPIVersion = &defaultValue
	}
	hostURL = strings.ReplaceAll(hostURL, "{livyApiVersion}", *livyAPIVersion)
	hostURL = strings.ReplaceAll(hostURL, "{sparkPoolName}", sparkPoolName)
	client := &batchClient{
		endpoint: hostURL,
		pl:       pl,
	}
	return client
}

// CancelSparkBatchJob - Cancels a running spark batch job.
// If the operation fails it returns an *azcore.ResponseError type.
// batchID - Identifier for the batch job.
// options - batchClientCancelSparkBatchJobOptions contains the optional parameters for the batchClient.CancelSparkBatchJob
// method.
func (client *batchClient) CancelSparkBatchJob(ctx context.Context, batchID int32, options *batchClientCancelSparkBatchJobOptions) (batchClientCancelSparkBatchJobResponse, error) {
	req, err := client.cancelSparkBatchJobCreateRequest(ctx, batchID, options)
	if err != nil {
		return batchClientCancelSparkBatchJobResponse{}, err
	}
	resp, err := client.pl.Do(req)
	if err != nil {
		return batchClientCancelSparkBatchJobResponse{}, err
	}
	if !runtime.HasStatusCode(resp, http.StatusOK) {
		return batchClientCancelSparkBatchJobResponse{}, runtime.NewResponseError(resp)
	}
	return batchClientCancelSparkBatchJobResponse{}, nil
}

// cancelSparkBatchJobCreateRequest creates the CancelSparkBatchJob request.
func (client *batchClient) cancelSparkBatchJobCreateRequest(ctx context.Context, batchID int32, options *batchClientCancelSparkBatchJobOptions) (*policy.Request, error) {
	urlPath := "/batches/{batchId}"
	urlPath = strings.ReplaceAll(urlPath, "{batchId}", url.PathEscape(strconv.FormatInt(int64(batchID), 10)))
	req, err := runtime.NewRequest(ctx, http.MethodDelete, runtime.JoinPaths(client.endpoint, urlPath))
	if err != nil {
		return nil, err
	}
	return req, nil
}

// CreateSparkBatchJob - Create new spark batch job.
// If the operation fails it returns an *azcore.ResponseError type.
// sparkBatchJobOptions - Livy compatible batch job request payload.
// options - batchClientCreateSparkBatchJobOptions contains the optional parameters for the batchClient.CreateSparkBatchJob
// method.
func (client *batchClient) CreateSparkBatchJob(ctx context.Context, sparkBatchJobOptions BatchJobOptions, options *batchClientCreateSparkBatchJobOptions) (batchClientCreateSparkBatchJobResponse, error) {
	req, err := client.createSparkBatchJobCreateRequest(ctx, sparkBatchJobOptions, options)
	if err != nil {
		return batchClientCreateSparkBatchJobResponse{}, err
	}
	resp, err := client.pl.Do(req)
	if err != nil {
		return batchClientCreateSparkBatchJobResponse{}, err
	}
	if !runtime.HasStatusCode(resp, http.StatusOK) {
		return batchClientCreateSparkBatchJobResponse{}, runtime.NewResponseError(resp)
	}
	return client.createSparkBatchJobHandleResponse(resp)
}

// createSparkBatchJobCreateRequest creates the CreateSparkBatchJob request.
func (client *batchClient) createSparkBatchJobCreateRequest(ctx context.Context, sparkBatchJobOptions BatchJobOptions, options *batchClientCreateSparkBatchJobOptions) (*policy.Request, error) {
	urlPath := "/batches"
	req, err := runtime.NewRequest(ctx, http.MethodPost, runtime.JoinPaths(client.endpoint, urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	if options != nil && options.Detailed != nil {
		reqQP.Set("detailed", strconv.FormatBool(*options.Detailed))
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header.Set("Accept", "application/json")
	return req, runtime.MarshalAsJSON(req, sparkBatchJobOptions)
}

// createSparkBatchJobHandleResponse handles the CreateSparkBatchJob response.
func (client *batchClient) createSparkBatchJobHandleResponse(resp *http.Response) (batchClientCreateSparkBatchJobResponse, error) {
	result := batchClientCreateSparkBatchJobResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.BatchJob); err != nil {
		return batchClientCreateSparkBatchJobResponse{}, err
	}
	return result, nil
}

// GetSparkBatchJob - Gets a single spark batch job.
// If the operation fails it returns an *azcore.ResponseError type.
// batchID - Identifier for the batch job.
// options - batchClientGetSparkBatchJobOptions contains the optional parameters for the batchClient.GetSparkBatchJob method.
func (client *batchClient) GetSparkBatchJob(ctx context.Context, batchID int32, options *batchClientGetSparkBatchJobOptions) (batchClientGetSparkBatchJobResponse, error) {
	req, err := client.getSparkBatchJobCreateRequest(ctx, batchID, options)
	if err != nil {
		return batchClientGetSparkBatchJobResponse{}, err
	}
	resp, err := client.pl.Do(req)
	if err != nil {
		return batchClientGetSparkBatchJobResponse{}, err
	}
	if !runtime.HasStatusCode(resp, http.StatusOK) {
		return batchClientGetSparkBatchJobResponse{}, runtime.NewResponseError(resp)
	}
	return client.getSparkBatchJobHandleResponse(resp)
}

// getSparkBatchJobCreateRequest creates the GetSparkBatchJob request.
func (client *batchClient) getSparkBatchJobCreateRequest(ctx context.Context, batchID int32, options *batchClientGetSparkBatchJobOptions) (*policy.Request, error) {
	urlPath := "/batches/{batchId}"
	urlPath = strings.ReplaceAll(urlPath, "{batchId}", url.PathEscape(strconv.FormatInt(int64(batchID), 10)))
	req, err := runtime.NewRequest(ctx, http.MethodGet, runtime.JoinPaths(client.endpoint, urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	if options != nil && options.Detailed != nil {
		reqQP.Set("detailed", strconv.FormatBool(*options.Detailed))
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header.Set("Accept", "application/json")
	return req, nil
}

// getSparkBatchJobHandleResponse handles the GetSparkBatchJob response.
func (client *batchClient) getSparkBatchJobHandleResponse(resp *http.Response) (batchClientGetSparkBatchJobResponse, error) {
	result := batchClientGetSparkBatchJobResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.BatchJob); err != nil {
		return batchClientGetSparkBatchJobResponse{}, err
	}
	return result, nil
}

// GetSparkBatchJobs - List all spark batch jobs which are running under a particular spark pool.
// If the operation fails it returns an *azcore.ResponseError type.
// options - batchClientGetSparkBatchJobsOptions contains the optional parameters for the batchClient.GetSparkBatchJobs method.
func (client *batchClient) GetSparkBatchJobs(ctx context.Context, options *batchClientGetSparkBatchJobsOptions) (batchClientGetSparkBatchJobsResponse, error) {
	req, err := client.getSparkBatchJobsCreateRequest(ctx, options)
	if err != nil {
		return batchClientGetSparkBatchJobsResponse{}, err
	}
	resp, err := client.pl.Do(req)
	if err != nil {
		return batchClientGetSparkBatchJobsResponse{}, err
	}
	if !runtime.HasStatusCode(resp, http.StatusOK) {
		return batchClientGetSparkBatchJobsResponse{}, runtime.NewResponseError(resp)
	}
	return client.getSparkBatchJobsHandleResponse(resp)
}

// getSparkBatchJobsCreateRequest creates the GetSparkBatchJobs request.
func (client *batchClient) getSparkBatchJobsCreateRequest(ctx context.Context, options *batchClientGetSparkBatchJobsOptions) (*policy.Request, error) {
	urlPath := "/batches"
	req, err := runtime.NewRequest(ctx, http.MethodGet, runtime.JoinPaths(client.endpoint, urlPath))
	if err != nil {
		return nil, err
	}
	reqQP := req.Raw().URL.Query()
	if options != nil && options.From != nil {
		reqQP.Set("from", strconv.FormatInt(int64(*options.From), 10))
	}
	if options != nil && options.Size != nil {
		reqQP.Set("size", strconv.FormatInt(int64(*options.Size), 10))
	}
	if options != nil && options.Detailed != nil {
		reqQP.Set("detailed", strconv.FormatBool(*options.Detailed))
	}
	req.Raw().URL.RawQuery = reqQP.Encode()
	req.Raw().Header.Set("Accept", "application/json")
	return req, nil
}

// getSparkBatchJobsHandleResponse handles the GetSparkBatchJobs response.
func (client *batchClient) getSparkBatchJobsHandleResponse(resp *http.Response) (batchClientGetSparkBatchJobsResponse, error) {
	result := batchClientGetSparkBatchJobsResponse{}
	if err := runtime.UnmarshalAsJSON(resp, &result.BatchJobCollection); err != nil {
		return batchClientGetSparkBatchJobsResponse{}, err
	}
	return result, nil
}
